{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01caf394",
   "metadata": {},
   "source": [
    "# Lesson 3: Data Modeling & Schema Design - Practice Notebook\n",
    "\n",
    "This notebook provides hands-on practice for designing optimal database schemas for ML feature engineering.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Lesson 1 (Data Pipelines)\n",
    "- Lesson 2 (BigQuery Deep Dive)\n",
    "- BigQuery with MLB data\n",
    "\n",
    "**What you'll learn:**\n",
    "- Star schema vs snowflake schema\n",
    "- Normalization vs denormalization\n",
    "- Creating fact and dimension tables\n",
    "- Building denormalized feature tables for ML\n",
    "- Schema optimization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6571c3d",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9aceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigQuery Configuration\n",
    "PROJECT_ID = \"hankstank\"\n",
    "DATASET = \"mlb_historical_data\"\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "print(f\"üîß Connected to project: {PROJECT_ID}\")\n",
    "print(f\"üìä Using dataset: {DATASET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960152bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from Lesson 2\n",
    "def run_query(query, show_cost=True, limit=10):\n",
    "    \"\"\"Execute a BigQuery query and return results as a DataFrame\"\"\"\n",
    "    try:\n",
    "        if show_cost:\n",
    "            job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "            dry_run_job = client.query(query, job_config=job_config)\n",
    "            bytes_processed = dry_run_job.total_bytes_processed\n",
    "            gb_processed = bytes_processed / 1e9\n",
    "            cost_estimate = (bytes_processed / 1e12) * 5\n",
    "            \n",
    "            print(f\"üìä Query will process: {gb_processed:.3f} GB\")\n",
    "            print(f\"üí∞ Estimated cost: ${cost_estimate:.6f}\\n\")\n",
    "        \n",
    "        df = client.query(query).to_dataframe()\n",
    "        print(f\"‚úÖ Query returned {len(df)} rows\")\n",
    "        \n",
    "        if limit and len(df) > limit:\n",
    "            print(f\"   (showing first {limit} rows)\\n\")\n",
    "            return df.head(limit)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Query error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde51039",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Analyze Current Schema\n",
    "\n",
    "Let's examine your current database schema to understand its structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f49ed",
   "metadata": {},
   "source": [
    "### Check All Tables in Your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb72959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all tables in your dataset\n",
    "dataset_ref = client.dataset(DATASET)\n",
    "tables = list(client.list_tables(dataset_ref))\n",
    "\n",
    "print(f\"üìã Tables in {DATASET}:\\n\")\n",
    "for table in tables:\n",
    "    table_ref = dataset_ref.table(table.table_id)\n",
    "    table_obj = client.get_table(table_ref)\n",
    "    print(f\"  {table.table_id:30s} - {table_obj.num_rows:,} rows, {table_obj.num_bytes / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912a5c0",
   "metadata": {},
   "source": [
    "### Examine games_historical Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae19b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_query = f\"\"\"\n",
    "SELECT \n",
    "  column_name,\n",
    "  data_type,\n",
    "  is_nullable\n",
    "FROM `{PROJECT_ID}.{DATASET}.INFORMATION_SCHEMA.COLUMNS`\n",
    "WHERE table_name = 'games_historical'\n",
    "ORDER BY ordinal_position\n",
    "\"\"\"\n",
    "\n",
    "schema_df = run_query(schema_query, show_cost=False, limit=None)\n",
    "display(schema_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8602899",
   "metadata": {},
   "source": [
    "### Sample Data from games_historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb7d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM `{PROJECT_ID}.{DATASET}.games_historical`\n",
    "ORDER BY game_date DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "sample_df = run_query(sample_query, show_cost=False, limit=None)\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e70c8ba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Create a Star Schema\n",
    "\n",
    "Let's design a star schema with fact and dimension tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b1e71",
   "metadata": {},
   "source": [
    "### Create Dimension Table: dim_teams\n",
    "\n",
    "Extract unique team information into a dimension table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Adjust column names based on your actual schema\n",
    "# This is a template - you'll need to modify based on the schema you saw above\n",
    "\n",
    "create_dim_teams = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.dim_teams` AS\n",
    "SELECT DISTINCT\n",
    "  team_id AS team_key,\n",
    "  team_name,\n",
    "  -- Add other team attributes here based on your data\n",
    "  -- city,\n",
    "  -- division,\n",
    "  -- league,\n",
    "  CURRENT_TIMESTAMP() AS created_at\n",
    "FROM (\n",
    "  SELECT DISTINCT home_team_id AS team_id, home_team_name AS team_name\n",
    "  FROM `{PROJECT_ID}.{DATASET}.games_historical`\n",
    "  WHERE home_team_id IS NOT NULL\n",
    "  \n",
    "  UNION DISTINCT\n",
    "  \n",
    "  SELECT DISTINCT away_team_id AS team_id, away_team_name AS team_name\n",
    "  FROM `{PROJECT_ID}.{DATASET}.games_historical`\n",
    "  WHERE away_team_id IS NOT NULL\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating dim_teams dimension table...\")\n",
    "print(\"\\n‚ö†Ô∏è  Review this query and adjust column names based on your schema before running!\\n\")\n",
    "print(create_dim_teams)\n",
    "\n",
    "# Uncomment when ready:\n",
    "# result = client.query(create_dim_teams)\n",
    "# print(\"‚úÖ dim_teams created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68586f26",
   "metadata": {},
   "source": [
    "### Create Dimension Table: dim_dates\n",
    "\n",
    "Create a date dimension with useful attributes for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8494125",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dim_dates = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.dim_dates` AS\n",
    "WITH date_range AS (\n",
    "  SELECT DISTINCT game_date AS date_key\n",
    "  FROM `{PROJECT_ID}.{DATASET}.games_historical`\n",
    "  WHERE game_date IS NOT NULL\n",
    ")\n",
    "SELECT \n",
    "  date_key,\n",
    "  EXTRACT(YEAR FROM date_key) AS year,\n",
    "  EXTRACT(MONTH FROM date_key) AS month,\n",
    "  EXTRACT(DAY FROM date_key) AS day,\n",
    "  EXTRACT(QUARTER FROM date_key) AS quarter,\n",
    "  FORMAT_DATE('%A', date_key) AS day_of_week,\n",
    "  FORMAT_DATE('%B', date_key) AS month_name,\n",
    "  EXTRACT(DAYOFWEEK FROM date_key) IN (1, 7) AS is_weekend,\n",
    "  EXTRACT(DAYOFYEAR FROM date_key) AS day_of_year,\n",
    "  CURRENT_TIMESTAMP() AS created_at\n",
    "FROM date_range\n",
    "ORDER BY date_key\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating dim_dates dimension table...\")\n",
    "print(create_dim_dates)\n",
    "\n",
    "# Uncomment when ready:\n",
    "# result = client.query(create_dim_dates)\n",
    "# print(\"‚úÖ dim_dates created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf803251",
   "metadata": {},
   "source": [
    "### Create Fact Table: fact_games\n",
    "\n",
    "Create a lean fact table with keys and measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde884fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fact_games = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.fact_games`\n",
    "PARTITION BY date_key\n",
    "CLUSTER BY home_team_key, away_team_key\n",
    "AS\n",
    "SELECT \n",
    "  game_pk,\n",
    "  game_date AS date_key,\n",
    "  home_team_id AS home_team_key,\n",
    "  away_team_id AS away_team_key,\n",
    "  \n",
    "  -- Measures (quantifiable metrics)\n",
    "  home_score,\n",
    "  away_score,\n",
    "  ABS(home_score - away_score) AS score_differential,\n",
    "  home_score + away_score AS total_runs,\n",
    "  \n",
    "  -- Flags\n",
    "  home_score > away_score AS home_won,\n",
    "  CASE \n",
    "    WHEN home_score > away_score THEN home_team_id\n",
    "    ELSE away_team_id\n",
    "  END AS winning_team_key,\n",
    "  \n",
    "  -- Metadata\n",
    "  season,\n",
    "  CURRENT_TIMESTAMP() AS created_at\n",
    "FROM `{PROJECT_ID}.{DATASET}.games_historical`\n",
    "WHERE game_date IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating fact_games fact table...\")\n",
    "print(\"\\n‚ö†Ô∏è  Review and adjust column names before running!\\n\")\n",
    "print(create_fact_games)\n",
    "\n",
    "# Uncomment when ready:\n",
    "# result = client.query(create_fact_games)\n",
    "# print(\"‚úÖ fact_games created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11cd38",
   "metadata": {},
   "source": [
    "### Query the Star Schema\n",
    "\n",
    "Now query using the star schema (fact + dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_schema_query = f\"\"\"\n",
    "SELECT \n",
    "  d.year,\n",
    "  d.month_name,\n",
    "  d.day_of_week,\n",
    "  ht.team_name AS home_team,\n",
    "  at.team_name AS away_team,\n",
    "  f.home_score,\n",
    "  f.away_score,\n",
    "  f.home_won\n",
    "FROM `{PROJECT_ID}.{DATASET}.fact_games` f\n",
    "JOIN `{PROJECT_ID}.{DATASET}.dim_dates` d \n",
    "  ON f.date_key = d.date_key\n",
    "JOIN `{PROJECT_ID}.{DATASET}.dim_teams` ht \n",
    "  ON f.home_team_key = ht.team_key\n",
    "JOIN `{PROJECT_ID}.{DATASET}.dim_teams` at \n",
    "  ON f.away_team_key = at.team_key\n",
    "WHERE d.year = 2026\n",
    "ORDER BY f.date_key DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "print(\"Querying star schema...\")\n",
    "# Uncomment after creating dimension and fact tables:\n",
    "# result = run_query(star_schema_query)\n",
    "# display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7d021",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Create Denormalized ML Feature Table\n",
    "\n",
    "The key to fast ML queries: denormalize everything into one table!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4dfa69",
   "metadata": {},
   "source": [
    "### Build ML Game Prediction Features\n",
    "\n",
    "This table combines raw data with rolling statistics in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c161b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_ml_features = f\"\"\"\n",
    "CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET}.ml_game_prediction_features`\n",
    "PARTITION BY game_date\n",
    "CLUSTER BY home_team_id, away_team_id\n",
    "AS\n",
    "WITH team_games AS (\n",
    "  -- Unpivot games to team-level view\n",
    "  SELECT \n",
    "    game_pk,\n",
    "    game_date,\n",
    "    season,\n",
    "    home_team_id AS team_id,\n",
    "    home_score AS runs_scored,\n",
    "    away_score AS runs_allowed,\n",
    "    CASE WHEN home_score > away_score THEN 1 ELSE 0 END AS won\n",
    "  FROM `{PROJECT_ID}.{DATASET}.games_historical`\n",
    "  \n",
    "  UNION ALL\n",
    "  \n",
    "  SELECT \n",
    "    game_pk,\n",
    "    game_date,\n",
    "    season,\n",
    "    away_team_id AS team_id,\n",
    "    away_score AS runs_scored,\n",
    "    home_score AS runs_allowed,\n",
    "    CASE WHEN away_score > home_score THEN 1 ELSE 0 END AS won\n",
    "  FROM `{PROJECT_ID}.{DATASET}.games_historical`\n",
    "),\n",
    "\n",
    "team_rolling_stats AS (\n",
    "  -- Calculate rolling statistics per team\n",
    "  SELECT \n",
    "    team_id,\n",
    "    game_date,\n",
    "    game_pk,\n",
    "    \n",
    "    -- Last 10 games stats\n",
    "    AVG(won) OVER w10 AS l10_win_pct,\n",
    "    AVG(runs_scored) OVER w10 AS l10_runs_scored,\n",
    "    AVG(runs_allowed) OVER w10 AS l10_runs_allowed,\n",
    "    \n",
    "    -- Season-to-date stats\n",
    "    SUM(won) OVER season AS season_wins,\n",
    "    COUNT(*) OVER season AS games_played,\n",
    "    SUM(runs_scored) OVER season AS season_runs_scored,\n",
    "    SUM(runs_allowed) OVER season AS season_runs_allowed\n",
    "    \n",
    "  FROM team_games\n",
    "  WINDOW \n",
    "    w10 AS (\n",
    "      PARTITION BY team_id, season \n",
    "      ORDER BY game_date \n",
    "      ROWS BETWEEN 9 PRECEDING AND CURRENT ROW\n",
    "    ),\n",
    "    season AS (\n",
    "      PARTITION BY team_id, season \n",
    "      ORDER BY game_date\n",
    "      ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "    )\n",
    ")\n",
    "\n",
    "-- Join everything together in denormalized form\n",
    "SELECT \n",
    "  g.game_pk,\n",
    "  g.game_date,\n",
    "  g.season,\n",
    "  \n",
    "  -- Home team features (denormalized)\n",
    "  g.home_team_id,\n",
    "  h.l10_win_pct AS home_l10_win_pct,\n",
    "  h.l10_runs_scored AS home_l10_runs_scored,\n",
    "  h.l10_runs_allowed AS home_l10_runs_allowed,\n",
    "  h.season_wins AS home_season_wins,\n",
    "  h.games_played AS home_games_played,\n",
    "  \n",
    "  -- Away team features (denormalized)\n",
    "  g.away_team_id,\n",
    "  a.l10_win_pct AS away_l10_win_pct,\n",
    "  a.l10_runs_scored AS away_l10_runs_scored,\n",
    "  a.l10_runs_allowed AS away_l10_runs_allowed,\n",
    "  a.season_wins AS away_season_wins,\n",
    "  a.games_played AS away_games_played,\n",
    "  \n",
    "  -- Matchup features (derived)\n",
    "  h.l10_win_pct - a.l10_win_pct AS win_pct_diff,\n",
    "  h.l10_runs_scored - a.l10_runs_scored AS runs_scored_diff,\n",
    "  a.l10_runs_allowed - h.l10_runs_allowed AS pitching_diff,\n",
    "  \n",
    "  -- Target variable\n",
    "  g.home_score,\n",
    "  g.away_score,\n",
    "  CASE WHEN g.home_score > g.away_score THEN 1 ELSE 0 END AS home_won,\n",
    "  \n",
    "  -- Metadata\n",
    "  CURRENT_TIMESTAMP() AS feature_created_at\n",
    "  \n",
    "FROM `{PROJECT_ID}.{DATASET}.games_historical` g\n",
    "LEFT JOIN team_rolling_stats h \n",
    "  ON g.game_pk = h.game_pk \n",
    "  AND g.home_team_id = h.team_id\n",
    "LEFT JOIN team_rolling_stats a \n",
    "  ON g.game_pk = a.game_pk \n",
    "  AND g.away_team_id = a.team_id\n",
    "WHERE g.game_date IS NOT NULL\n",
    "ORDER BY g.game_date DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"Creating ml_game_prediction_features table...\")\n",
    "print(\"\\n‚ö†Ô∏è  This creates a denormalized feature table optimized for ML!\\n\")\n",
    "print(\"\\nüîç Review the query structure before running\\n\")\n",
    "\n",
    "# Uncomment when ready:\n",
    "# result = client.query(create_ml_features)\n",
    "# print(\"‚úÖ ml_game_prediction_features created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a474ff",
   "metadata": {},
   "source": [
    "### Query the ML Feature Table\n",
    "\n",
    "Now querying is simple - no joins needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af17037",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_query = f\"\"\"\n",
    "SELECT \n",
    "  game_date,\n",
    "  home_team_id,\n",
    "  away_team_id,\n",
    "  home_l10_win_pct,\n",
    "  away_l10_win_pct,\n",
    "  win_pct_diff,\n",
    "  home_score,\n",
    "  away_score,\n",
    "  home_won\n",
    "FROM `{PROJECT_ID}.{DATASET}.ml_game_prediction_features`\n",
    "WHERE season = 2026\n",
    "  AND home_l10_win_pct IS NOT NULL\n",
    "  AND away_l10_win_pct IS NOT NULL\n",
    "ORDER BY game_date DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "print(\"Querying denormalized ML features (no joins!)...\")\n",
    "# Uncomment after creating the feature table:\n",
    "# result = run_query(ml_query)\n",
    "# display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c0d3cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Performance Comparison\n",
    "\n",
    "Let's benchmark normalized vs denormalized queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c11e9f",
   "metadata": {},
   "source": [
    "### Benchmark: Normalized Query (Multiple Joins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Normalized query with joins\n",
    "normalized_query = f\"\"\"\n",
    "SELECT \n",
    "  f.date_key,\n",
    "  ht.team_name AS home_team,\n",
    "  at.team_name AS away_team,\n",
    "  d.day_of_week,\n",
    "  f.home_score,\n",
    "  f.away_score\n",
    "FROM `{PROJECT_ID}.{DATASET}.fact_games` f\n",
    "JOIN `{PROJECT_ID}.{DATASET}.dim_teams` ht ON f.home_team_key = ht.team_key\n",
    "JOIN `{PROJECT_ID}.{DATASET}.dim_teams` at ON f.away_team_key = at.team_key\n",
    "JOIN `{PROJECT_ID}.{DATASET}.dim_dates` d ON f.date_key = d.date_key\n",
    "WHERE d.year = 2026\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚è±Ô∏è  Running normalized query (with joins)...\")\n",
    "# Uncomment to test:\n",
    "# start = time.time()\n",
    "# result_norm = run_query(normalized_query, show_cost=True, limit=5)\n",
    "# norm_time = time.time() - start\n",
    "# print(f\"Execution time: {norm_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c624b5a",
   "metadata": {},
   "source": [
    "### Benchmark: Denormalized Query (No Joins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa406e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalized query - no joins!\n",
    "denormalized_query = f\"\"\"\n",
    "SELECT \n",
    "  game_date,\n",
    "  home_team_id,\n",
    "  away_team_id,\n",
    "  home_l10_win_pct,\n",
    "  away_l10_win_pct,\n",
    "  home_score,\n",
    "  away_score\n",
    "FROM `{PROJECT_ID}.{DATASET}.ml_game_prediction_features`\n",
    "WHERE season = 2026\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚è±Ô∏è  Running denormalized query (no joins)...\")\n",
    "# Uncomment to test:\n",
    "# start = time.time()\n",
    "# result_denorm = run_query(denormalized_query, show_cost=True, limit=5)\n",
    "# denorm_time = time.time() - start\n",
    "# print(f\"Execution time: {denorm_time:.2f} seconds\")\n",
    "# print(f\"\\nüöÄ Speedup: {norm_time / denorm_time:.1f}x faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeb6168",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Practice Exercises\n",
    "\n",
    "Now it's your turn to design schemas!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e63753",
   "metadata": {},
   "source": [
    "### Exercise 1: Create a Player Dimension Table\n",
    "\n",
    "Design and create a `dim_players` table with player attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Create dim_players\n",
    "# Hint: Extract unique players from player_stats_historical or similar table\n",
    "# Include: player_id, full_name, position, bats, throws, etc.\n",
    "\n",
    "exercise_1_query = \"\"\"\n",
    "-- Write your CREATE TABLE query here\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment when ready:\n",
    "# result = client.query(exercise_1_query)\n",
    "# print(\"‚úÖ dim_players created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58617ddc",
   "metadata": {},
   "source": [
    "### Exercise 2: Create Player Performance Feature Table\n",
    "\n",
    "Build a denormalized table for player batting prediction with rolling stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c860bb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create ml_player_batting_features\n",
    "# Include:\n",
    "# - player_id, player_name, game_date\n",
    "# - last_10_games_batting_avg\n",
    "# - last_10_games_home_runs\n",
    "# - season_to_date_stats\n",
    "# - opponent_pitcher_stats\n",
    "\n",
    "exercise_2_query = \"\"\"\n",
    "-- Write your feature engineering query here\n",
    "-- Use window functions for rolling statistics\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment when ready:\n",
    "# result = client.query(exercise_2_query)\n",
    "# print(\"‚úÖ ml_player_batting_features created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d71ecc",
   "metadata": {},
   "source": [
    "### Exercise 3: Design Your Own Schema\n",
    "\n",
    "Choose a prediction task and design an optimal schema for it.\n",
    "\n",
    "Ideas:\n",
    "- Pitcher strikeout prediction\n",
    "- Player home run prediction  \n",
    "- Team runs scored prediction\n",
    "- Win streak prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37352aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Design your own ML feature table\n",
    "# Think about:\n",
    "# 1. What are you predicting? (target variable)\n",
    "# 2. What features would be useful?\n",
    "# 3. What rolling statistics make sense?\n",
    "# 4. What time windows? (last 5, 10, 20 games?)\n",
    "\n",
    "exercise_3_query = \"\"\"\n",
    "-- Your creative schema design here!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment when ready:\n",
    "# result = client.query(exercise_3_query)\n",
    "# print(\"‚úÖ Your custom feature table created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33de03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What you learned:**\n",
    "- ‚úÖ Star schema design (fact + dimension tables)\n",
    "- ‚úÖ Normalization vs denormalization tradeoffs\n",
    "- ‚úÖ Creating denormalized ML feature tables\n",
    "- ‚úÖ Performance benefits of denormalization\n",
    "- ‚úÖ Designing schemas for specific ML tasks\n",
    "\n",
    "**Key Insights:**\n",
    "1. **Normalize for storage**, denormalize for ML queries\n",
    "2. **Star schema** is ideal for BigQuery analytics\n",
    "3. **Denormalized feature tables** are 10-100x faster\n",
    "4. **Partition and cluster** feature tables for best performance\n",
    "5. **Window functions** in feature creation enable powerful rolling stats\n",
    "\n",
    "**Next Steps:**\n",
    "1. Create the dimension and fact tables for your data\n",
    "2. Build your first denormalized ML feature table\n",
    "3. Benchmark query performance improvements\n",
    "4. Design feature tables for your specific ML use cases\n",
    "5. **Move to Lesson 4:** Workflow Orchestration\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to design lightning-fast ML schemas? Run the exercises above!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
